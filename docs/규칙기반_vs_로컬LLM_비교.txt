[규칙기반(1번) vs 로컬 LLM/Ollama(2번) 상세 비교]

작성 목적
- 로봇 음성 응답 시스템에서 비용, 지연, 안정성, 유지보수 관점으로 두 방식을 비교해
  어떤 구조가 실제 운영에 효율적인지 판단하기 위함.

--------------------------------------------------
1. 정의
--------------------------------------------------

1) 규칙기반 응답 (Rule-based)
- 입력 문장에 특정 키워드/패턴이 포함되면 미리 정해둔 답변을 반환.
- 예: "안녕" -> "안녕하세요. 무엇을 도와드릴까요?"
- 현재 voice_reply_cpp의 rules 파라미터 방식이 여기에 해당.

2) 로컬 LLM 응답 (Ollama 등)
- 로컬 PC/Jetson에서 LLM을 실행하고, 입력 텍스트를 모델에 질의해 답변 생성.
- 인터넷/클라우드 API 없이 동작 가능.
- 예: Ollama로 qwen2.5:3b, llama3.2:3b 등을 로컬 추론.

--------------------------------------------------
2. 핵심 차이 한눈에 보기
--------------------------------------------------

[규칙기반]
- 장점: 매우 빠름, 매우 안정적, 비용 0, 동작 예측 쉬움
- 단점: 유연성 낮음, 표현 다양성 부족, 예상 못한 질문에 취약

[로컬 LLM]
- 장점: 자연어 이해/생성 유연함, 다양한 질문 대응 가능
- 단점: 추론 지연 증가, 자원 사용 큼(CPU/GPU/RAM), 답변 일관성 관리 필요

--------------------------------------------------
3. 비용(운영비) 비교
--------------------------------------------------

1) 규칙기반
- 추가 과금 없음.
- 전기/장비 비용 외 별도 API 비용 없음.
- 가장 저비용.

2) 로컬 LLM
- API 과금은 없지만 하드웨어 부담이 큼.
- 보드 성능이 낮으면 느리거나 모델 크기를 줄여야 함.
- 장기적으로는 클라우드 API보다 비용 예측이 쉬움.

정리
- "돈" 기준 최저는 둘 다 0원 운영 가능하지만,
  규칙기반은 하드웨어 부담까지 최소라 총비용이 가장 낮음.

--------------------------------------------------
4. 지연시간(체감 속도) 비교
--------------------------------------------------

1) 규칙기반
- 문자열 매칭 수준이라 매우 빠름(보통 거의 즉시).
- 음성 UX에서 즉답형 명령(정지/출발/상태 질의)에 매우 유리.

2) 로컬 LLM
- 모델 크기, 장치 성능, 문장 길이에 따라 지연 발생.
- 저사양 환경에서는 답변이 느려 체감 품질 저하 가능.

정리
- 실시간 제어/안전 명령은 규칙기반이 압도적으로 유리.

--------------------------------------------------
5. 정확성/예측 가능성 비교
--------------------------------------------------

1) 규칙기반
- 입력이 규칙에 맞으면 항상 같은 결과.
- 예측 가능성 최고, 테스트/검증이 쉬움.
- 다만 규칙 밖 질문은 처리 어려움.

2) 로컬 LLM
- 맥락 기반 답변 가능해 유연하지만,
  같은 질문에도 표현이 바뀌거나 부정확한 답을 할 수 있음.
- 안전한 시스템에는 가드레일/후처리 필요.

정리
- "절대 틀리면 안 되는 명령"은 규칙기반 우선이 맞음.

--------------------------------------------------
6. 유지보수 난이도 비교
--------------------------------------------------

1) 규칙기반
- 초기 구현/디버그 쉬움.
- 도메인이 커질수록 규칙 증가로 관리 복잡도 상승.
- 그래도 원인 추적(왜 이런 응답이 나왔는지)이 명확.

2) 로컬 LLM
- 초기 설치(모델, 런타임, 자원 튜닝) 필요.
- 프롬프트/모델 버전에 따라 품질 편차 관리 필요.
- 디버깅 시 "왜 이런 답변이 나왔는지"가 규칙기반보다 불명확.

--------------------------------------------------
7. 오프라인/네트워크 의존성
--------------------------------------------------

1) 규칙기반
- 완전 오프라인 가능.

2) 로컬 LLM
- 로컬 모델이면 오프라인 가능.
- (클라우드 API LLM은 인터넷 필수)

정리
- 오프라인 요구가 강하면 둘 다 가능하나,
  규칙기반이 더 가볍고 실패 포인트가 적음.

--------------------------------------------------
8. 리소스 사용량(CPU/GPU/RAM)
--------------------------------------------------

1) 규칙기반
- 매우 낮음.
- 다른 센서/제어 노드에 거의 영향 없음.

2) 로컬 LLM
- 상대적으로 높음.
- 카메라/SLAM/인식 동시 실행 시 자원 경합 가능.

정리
- 로봇 멀티노드 시스템에서는 로컬 LLM 사용 시 리소스 예산 계획 필수.

--------------------------------------------------
9. 장애 대응/복구 관점
--------------------------------------------------

1) 규칙기반
- 장애 지점이 단순해서 복구 용이.
- 응답 실패 시 원인 파악 빠름.

2) 로컬 LLM
- 모델 로딩 실패, OOM, 추론 지연 등 장애 형태가 다양.
- watchdog/timeout/fallback 전략이 꼭 필요.

--------------------------------------------------
10. 어떤 상황에서 무엇이 적합한가
--------------------------------------------------

규칙기반이 적합
- 정해진 명령어 세트(정지, 이동, 상태 확인 등)
- 즉시성/안정성이 최우선
- 저사양 하드웨어
- 운영 복잡도를 낮추고 싶을 때

로컬 LLM이 적합
- 자유 질의응답이 필요
- 대화형 인터랙션 품질을 높이고 싶을 때
- 어느 정도 지연/변동성 허용 가능
- 장치 자원이 충분할 때

--------------------------------------------------
11. 실제 운영 추천: 하이브리드
--------------------------------------------------

추천 구조
1) 1차: 규칙기반
   - 안전/제어/자주 쓰는 명령은 즉시 처리
2) 2차: 로컬 LLM
   - 규칙 미매칭 문장만 LLM으로 처리
3) 실패 시
   - "다시 말씀해 주세요" 또는 짧은 안내 문구 fallback

장점
- 속도 + 안정성 + 유연성 동시 확보
- 비용 0원 유지 가능(API 과금 없음)
- 현장 운영에서 장애 전파를 줄임

--------------------------------------------------
12. 결론
--------------------------------------------------

- 순수 효율(속도/안정/비용)만 보면 1번 규칙기반이 가장 효율적.
- 사용자 경험(자유대화)까지 고려하면 2번 로컬 LLM이 필요.
- 따라서 실전에서는 "규칙기반 우선 + 로컬 LLM 보조"가 가장 효율적인 선택.

