# ğŸš€ ë¹ ë¥¸ ë³µêµ¬ ê°€ì´ë“œ (5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°)

**ì‘ì„±ì¼**: 2026-03-01
**ìƒí™©**: STT/TTS/LLM ê²€ì¦ ì‹¤íŒ¨ í›„ ì¦‰ì‹œ ë³µêµ¬
**ëª©í‘œ**: ìµœì†Œí•œì˜ ìŒì„± íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ë³´

---

## âš¡ ì¦‰ì‹œ ì‹¤í–‰ (ë³µì‚¬ & ë¶™ì—¬ë„£ê¸°)

### 1ë‹¨ê³„: TTS ì˜ì¡´ì„± ì„¤ì¹˜ (2ë¶„)

```bash
cd /home/sang/dev_ws/AI_secretary_robot
bash scripts/setup_tts_dependencies.sh
```

**ì„¤ì¹˜ ë‚´ì—­**:
- âœ… espeak-ng (í•œêµ­ì–´ fallback TTS)
- âœ… edge-tts (í´ë¼ìš°ë“œ TTS, ì„ íƒì )
- âœ… piper (ë¡œì»¬ ONNX TTS, ê³ ìŒì§ˆ)

**ì˜ˆìƒ ì‹œê°„**: 2ë¶„

---

### 2ë‹¨ê³„: LLM ì˜ì¡´ì„± ì„¤ì¹˜ (10ë¶„)

```bash
cd /home/sang/dev_ws/AI_secretary_robot
bash scripts/setup_llm_dependencies.sh
```

**ì„¤ì¹˜ ë‚´ì—­**:
- âœ… Ollama (ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥)
- âœ… Qwen2.5:1.5b ëª¨ë¸ (1.2GB)
- âš ï¸ llama.cpp ë¹Œë“œ (30ë¶„ ì†Œìš”, ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)

**ì˜ˆìƒ ì‹œê°„**:
- Ollama ì„¤ì¹˜: 5ë¶„
- llama.cpp ë¹Œë“œ: 30ë¶„ (ë°±ê·¸ë¼ìš´ë“œ)

---

### 3ë‹¨ê³„: ê²€ì¦ í…ŒìŠ¤íŠ¸ (1ë¶„)

```bash
cd /home/sang/dev_ws/AI_secretary_robot
source install/setup.bash

# TTS í…ŒìŠ¤íŠ¸
ros2 launch tts_cpp tts.launch.py &
sleep 3
ros2 topic pub /tts/text std_msgs/String "data: 'ì•ˆë…•í•˜ì„¸ìš”'" --once

# LLM í…ŒìŠ¤íŠ¸
ros2 launch llm_cpp llm.launch.py &
sleep 3
ros2 topic pub /intent_router/chat_text std_msgs/String "data: 'ìê¸°ì†Œê°œí•´ì¤˜'" --once
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
[tts_node]: TTS engine: espeak-ng
[tts_node]: Audio saved: /tmp/tts_audio/tts_xxxxx.wav
[llm_node]: LLM provider: ollama
[llm_node]: Response: {"intent": "chat", "response": "ì•ˆë…•í•˜ì„¸ìš”!..."}
```

---

## ğŸ“Š ì„¤ì¹˜ í›„ í™•ì¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### TTS ì—”ì§„ ìƒíƒœ
```bash
# espeak-ng í™•ì¸
espeak-ng --version
# ê¸°ëŒ€: eSpeak NG text-to-speech: 1.50

# edge-tts í™•ì¸
python3 -c "import edge_tts; print('âœ… edge-tts installed')"

# piper í™•ì¸
piper --version
# ê¸°ëŒ€: piper version 1.2.0
```

### LLM ì—”ì§„ ìƒíƒœ
```bash
# Ollama í™•ì¸
ollama list
# ê¸°ëŒ€: qwen2.5:1.5b  1.2GB  ...

# llama-server í™•ì¸ (ë¹Œë“œ ì™„ë£Œ í›„)
llama-server --version
# ê¸°ëŒ€: llama server

# llama.cpp ë¹Œë“œ ì§„í–‰ ìƒíƒœ (ë°±ê·¸ë¼ìš´ë“œ)
tail -f /tmp/llama_cpp_build.log  # (ë¹Œë“œ ì¤‘ì¼ ê²½ìš°)
```

---

## ğŸ¯ Phaseë³„ ë³µêµ¬ ì „ëµ

### Phase 1: ìµœì†Œ ë™ì‘ (5ë¶„) âœ…
**ëª©í‘œ**: espeak-ng + Ollamaë¡œ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë™ì‘

```bash
# ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…:
âœ… espeak-ng ì„¤ì¹˜
âœ… Ollama ì„¤ì¹˜
âœ… Qwen2.5:1.5b ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

# ë™ì‘ ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸:
ìŒì„± ì…ë ¥ â†’ STT (Moonshine) â†’ LLM (Ollama) â†’ TTS (espeak-ng) â†’ ìŒì„± ì¶œë ¥
```

**ì œì•½**:
- TTS ìŒì§ˆ: ë‚®ìŒ (espeak-ngëŠ” ë¡œë´‡í‹±í•œ ìŒì„±)
- LLM ì˜ì¡´ì„±: Ollama ë°ëª¬ í•„ìš”

---

### Phase 2: ìŒì§ˆ ê°œì„  (ì¶”ê°€ 0ë¶„) âœ…
**ëª©í‘œ**: Piper TTSë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±

```bash
# ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…:
âœ… piper ë°”ì´ë„ˆë¦¬ ì„¤ì¹˜
âœ… Piper ëª¨ë¸ ì¡´ì¬ (61MB ONNX)

# TTS ì—”ì§„ ë³€ê²½
ros2 param set /tts_node tts_engine "piper"
ros2 topic pub /tts/text std_msgs/String "data: 'íŒŒì´í¼ ìŒì„±ì…ë‹ˆë‹¤'" --once

# ê¸°ëŒ€: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìŒì„± (MOS 4.0/5.0 ìˆ˜ì¤€)
```

---

### Phase 3: ë¡œì»¬ LLM (ì¶”ê°€ 30ë¶„) â³
**ëª©í‘œ**: llama.cpp ì§ì ‘ ì¶”ë¡  (Planning ë¬¸ì„œ ì¤€ìˆ˜)

```bash
# ë°±ê·¸ë¼ìš´ë“œ ë¹Œë“œ ëŒ€ê¸° (30ë¶„)
# scripts/setup_llm_dependencies.sh ì‹¤í–‰ ì¤‘...

# ë¹Œë“œ ì™„ë£Œ í›„:
llama-server \
  --model /home/sang/dev_ws/AI_secretary_robot/models/llm/qwen2.5-1.5b-instruct-q4_k_m.gguf \
  --port 8081 \
  -ngl 99 &

# ROS2 ë…¸ë“œì—ì„œ llama.cpp ì‚¬ìš©
# (params.yaml ìˆ˜ì • í›„ ì¬ì‹œì‘ í•„ìš”)
```

---

## ğŸ”¥ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… (1ë¶„ ì•ˆì— í•´ê²°)

### 1. TTS ìŒì„± ì¬ìƒ ì•ˆ ë¨
**ì¦ìƒ**: `aplay` ì—ëŸ¬ ë©”ì‹œì§€

**í•´ê²°**:
```bash
# ALSA ì¥ì¹˜ í™•ì¸
aplay -l

# ê¸°ë³¸ ì¥ì¹˜ ë³€ê²½
export ALSA_CARD=0  # ë˜ëŠ” ì‹¤ì œ ì¹´ë“œ ë²ˆí˜¸

# ROS2 íŒŒë¼ë¯¸í„° ë³€ê²½
ros2 param set /tts_node alsa_device "plughw:CARD=Device,DEV=0"
```

---

### 2. Ollama ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**: `Failed to connect to Ollama`

**í•´ê²°**:
```bash
# Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status ollama

# ìˆ˜ë™ ì‹œì‘
ollama serve &

# ì—°ê²° í…ŒìŠ¤íŠ¸
curl http://localhost:11434/api/tags
```

---

### 3. piper ì‹¤í–‰ ì‹¤íŒ¨
**ì¦ìƒ**: `piper: command not found`

**í•´ê²°**:
```bash
# PATH í™•ì¸
which piper
# ì—†ìœ¼ë©´ ìˆ˜ë™ ì„¤ì¹˜:
sudo ln -sf /usr/local/bin/piper /usr/bin/piper

# ë˜ëŠ” ì „ì²´ ê²½ë¡œ ì‚¬ìš©
ros2 param set /tts_node piper_executable "/usr/local/bin/piper"
```

---

### 4. llama.cpp ë¹Œë“œ ì‹¤íŒ¨
**ì¦ìƒ**: `CMake error: CUDA not found`

**í•´ê²°**:
```bash
# CUDA ê²½ë¡œ í™•ì¸
nvcc --version

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH

# ë¹Œë“œ ì¬ì‹œë„
cd /home/sang/dev_ws/AI_secretary_robot/external/llama.cpp/build
cmake .. -DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=87
make -j$(nproc)
```

---

## ğŸ“ ê¸´ê¸‰ ì§€ì› ëª…ë ¹ì–´

### ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¬ì‹œì‘
```bash
# ëª¨ë“  ROS2 ë…¸ë“œ ì¢…ë£Œ
pkill -f ros2

# Ollama ì¬ì‹œì‘
sudo systemctl restart ollama

# ROS2 ë…¸ë“œ ì¬ì‹œì‘
cd /home/sang/dev_ws/AI_secretary_robot
source install/setup.bash
ros2 launch tts_cpp voice_pipeline_local.launch.py
```

### ë¡œê·¸ í™•ì¸
```bash
# TTS ë¡œê·¸
cat ~/.ros/log/latest/tts_node/stdout.log | tail -50

# LLM ë¡œê·¸
cat ~/.ros/log/latest/llm_node/stdout.log | tail -50

# Ollama ë¡œê·¸
journalctl -u ollama -n 50

# llama-server ë¡œê·¸ (ì‹¤í–‰ ì¤‘ì¼ ê²½ìš°)
cat /tmp/llama_server_8081.log
```

### ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸
```bash
# GPU ì‚¬ìš©ëŸ‰
nvidia-smi

# Jetson í†µí•© ëª¨ë‹ˆí„°ë§
tegrastats

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
free -h

# ë””ìŠ¤í¬ ê³µê°„
df -h
```

---

## âœ… ìµœì¢… í™•ì¸ (ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ í›„)

### ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
```bash
cd /home/sang/dev_ws/AI_secretary_robot
source install/setup.bash

# ìŒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
ros2 launch tts_cpp voice_pipeline_local.launch.py

# ë³„ë„ í„°ë¯¸ë„ì—ì„œ:
# 1. Wake Word ì‹œë®¬ë ˆì´ì…˜
ros2 topic pub /wake_vad/detected std_msgs/Bool "data: true" --once

# 2. ìŒì„± ì…ë ¥ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ë§ˆì´í¬ ëŒ€ì‹ )
ros2 topic pub /stt/text std_msgs/String "data: 'ë¡œë´‡ íŒ” ë“¤ì–´'" --once

# 3. ê¸°ëŒ€ ì¶œë ¥:
# - /llm/response: {"intent": "manipulator_move", ...}
# - /tts/audio_path: /tmp/tts_audio/tts_xxxxx.wav
# - ìŠ¤í”¼ì»¤ì—ì„œ ì‘ë‹µ ìŒì„± ì¬ìƒ
```

---

## ğŸŠ ì„±ê³µ ê¸°ì¤€

### Phase 1 ì™„ë£Œ (ìµœì†Œ ë™ì‘)
- âœ… espeak-ng TTS ìŒì„± ì¬ìƒ ì„±ê³µ
- âœ… Ollama LLM ì¶”ë¡  ì„±ê³µ
- âœ… ROS2 í† í”½ `/tts/text` â†’ `/llm/response` ì—°ê²°

### Phase 2 ì™„ë£Œ (ìŒì§ˆ ê°œì„ )
- âœ… Piper TTS ìŒì„± ì¬ìƒ ì„±ê³µ
- âœ… ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë°œìŒ í™•ì¸
- âœ… TTS ì§€ì—°ì‹œê°„ < 200ms

### Phase 3 ì™„ë£Œ (ë¡œì»¬ LLM)
- âœ… llama-server ì‹¤í–‰ ì„±ê³µ
- âœ… GGUF ëª¨ë¸ ë¡œë”© ì„±ê³µ
- âœ… GPU ì˜¤í”„ë¡œë”© í™•ì¸ (`-ngl 99`)
- âœ… LLM ì¶”ë¡  ì†ë„ 15~25ms/í† í°

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- **ìƒì„¸ ê°€ì´ë“œ**: [migration_recovery_guide.md](./migration_recovery_guide.md)
- **Codex í”„ë¡¬í”„íŠ¸**:
  - [STT sherpa-onnx ë§ˆì´ê·¸ë ˆì´ì…˜](./codex_prompt_stt_sherpa_migration.md)
  - [TTS sherpa-onnx ë§ˆì´ê·¸ë ˆì´ì…˜](./codex_prompt_tts_sherpa_migration.md)
  - [LLM llama.cpp ë§ˆì´ê·¸ë ˆì´ì…˜](./codex_prompt_llm_llamacpp_migration.md)
- **Planning ë¬¸ì„œ**: [plan.md](./plan.md)

---

**ì‘ì„±ì ë…¸íŠ¸**:
ì´ ê°€ì´ë“œëŠ” **5ë¶„ ì•ˆì— ìµœì†Œ ë™ì‘ íŒŒì´í”„ë¼ì¸ì„ ë³µêµ¬**í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. Phase 1ë§Œ ì™„ë£Œí•´ë„ ìŒì„± ëª…ë ¹ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë©°, Phase 2/3ëŠ” í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ ì„ íƒì  ë‹¨ê³„ì…ë‹ˆë‹¤. ë¬¸ì œ ë°œìƒ ì‹œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì„¹ì…˜ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.
